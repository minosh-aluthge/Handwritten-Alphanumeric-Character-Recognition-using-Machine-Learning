# LeNet-5 Improved Model Guide

## üéØ Goal
Achieve higher validation accuracy in the tuned model compared to the baseline model.

## ‚ùå Previous Problem
The original "tuned" model had **too much regularization**:
- Dropout: 0.2 - 0.5 (too high!)
- L2 regularization: 1e-4 to 1e-2 (too aggressive!)
- Result: **Underfitting** - tuned model performed worse than baseline

## ‚úÖ Solution

### Quick Improved Model (Recommended)
**Location:** Cell after "Quick Improved Model (No Tuning Required)" markdown

**Key Changes:**
1. **Reduced Dropout**: 0.1-0.2 instead of 0.2-0.5
2. **Lighter L2 Regularization**: 1e-4 instead of 1e-3 to 1e-2
3. **Added BatchNormalization**: Better training stability
4. **Wider Dense Layers**: 128 units for more capacity
5. **Better Learning Rate**: 1e-3 with ReduceLROnPlateau
6. **More Epochs with Patience**: 60 epochs with early stopping patience=12

**Expected Results:**
- Validation Accuracy: **85-88%+**
- Should **outperform baseline** by 2-5 percentage points

### Full Hyperparameter Search (Optional)
**Location:** "Improved Hyperparameter tuning" cell

Uses Keras Tuner to search:
- 15 trials with 2 executions each
- Balanced search space (not over-regularized)
- Takes longer but finds optimal settings

## üìä How to Use

### Option 1: Quick Results (5-10 minutes)
```
1. Run cell 1 (paths setup)
2. Run cell 3 (load datasets)  
3. Run cell 6 (baseline model - for comparison)
4. Run "Quick Improved Model" cell
5. Run comparison cell to see improvement
```

### Option 2: Full Hyperparameter Search (30+ minutes)
```
1. Run cell 1 (paths setup)
2. Run cell 3 (load datasets)
3. Run cell 6 (baseline model - for comparison)
4. Run "Improved hyperparameter tuning" cell
5. Run "Retrieve best hyperparameters" cell
6. Run comparison cell
```

## üîë Key Insights

### Why Original Tuning Failed
- **Over-regularization**: High dropout + high L2 = model can't learn patterns
- **Too conservative**: Model capacity was reduced too much
- **Wrong objective**: Focused on preventing overfitting when there was none

### Why New Approach Works
- **Balanced regularization**: Just enough to prevent overfitting
- **More capacity**: Wider layers can learn complex character patterns
- **BatchNorm**: Stabilizes training and acts as light regularization
- **Adaptive LR**: ReduceLROnPlateau finds optimal learning rate automatically

## üìà Expected Improvements

| Metric | Baseline | Old Tuned | New Improved |
|--------|----------|-----------|--------------|
| Val Accuracy | 85% | 80% ‚ùå | 87%+ ‚úÖ |
| Overfitting | Slight | None | Minimal |
| Training Time | 5 min | 10 min | 8 min |

## üöÄ Advanced Tips

### 1. Data Augmentation
Add to dataset pipeline for +1-2% accuracy:
```python
augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomRotation(0.05),
    tf.keras.layers.RandomTranslation(0.05, 0.05),
])
```

### 2. Larger Model
Increase capacity:
- Conv1: 6 ‚Üí 12 filters
- Conv2: 16 ‚Üí 32 filters  
- Dense: 128 ‚Üí 256 units

### 3. Learning Rate Schedule
Use cosine decay for better convergence:
```python
lr_schedule = tf.keras.optimizers.schedules.CosineDecay(
    initial_learning_rate=1e-3,
    decay_steps=1000
)
```

### 4. Ensemble
Train 3-5 models and average predictions for +2-3% accuracy

## üêõ Troubleshooting

### Model still underfitting?
- Reduce dropout to 0.05-0.1
- Remove L2 regularization
- Increase dense units to 256

### Model overfitting?
- Add slight data augmentation
- Increase dropout to 0.25-0.3
- Add L2 regularization 5e-4

### Not improving over baseline?
- Check if baseline is already optimal
- Try increasing model capacity first
- Consider data quality issues

## üìù Summary

The key to better tuned model performance is **balanced regularization**:
- ‚úÖ Use BatchNorm (free regularization + stability)
- ‚úÖ Light dropout (0.1-0.2)
- ‚úÖ Light L2 (1e-5 to 1e-4)
- ‚úÖ Adaptive learning rate
- ‚úÖ More capacity (wider layers)

**Don't over-regularize!** The original model suffered from too much regularization, preventing it from learning effectively.
