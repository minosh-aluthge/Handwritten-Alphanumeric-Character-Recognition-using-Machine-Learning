{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e161dd",
   "metadata": {},
   "source": [
    "# Generate HOG Features for SVM Training (48x48)\n",
    "\n",
    "This notebook extracts HOG (Histogram of Oriented Gradients) features from all images and saves them to disk.\n",
    "\n",
    "**Purpose**: Run this notebook ONCE to generate HOG features, then use the saved features in `svm hog.ipynb` for faster training.\n",
    "\n",
    "**Image Size**: 48x48 (testing medium-small resolution for optimal balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c92c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d93b3",
   "metadata": {},
   "source": [
    "## Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e2d4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path: /home/ubuntu/Desktop/AIML project/AlphaNum3/train\n",
      "Validation path: /home/ubuntu/Desktop/AIML project/AlphaNum3/validation\n",
      "Test path: /home/ubuntu/Desktop/AIML project/AlphaNum3/test\n",
      "HOG features will be saved to: /home/ubuntu/Desktop/AIML project/AlphaNum/hog_features\n"
     ]
    }
   ],
   "source": [
    "# Define dataset paths\n",
    "BASE_PATH = '/home/ubuntu/Desktop/AIML project/AlphaNum3'\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, \"train\")\n",
    "VALIDATION_PATH = os.path.join(BASE_PATH, \"validation\")\n",
    "TEST_PATH = os.path.join(BASE_PATH, \"test\")\n",
    "\n",
    "# Define output directory for HOG features\n",
    "HOG_OUTPUT_PATH = '/home/ubuntu/Desktop/AIML project/AlphaNum/hog_features'\n",
    "os.makedirs(HOG_OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Print paths for verification\n",
    "print(f\"Train path: {TRAIN_PATH}\")\n",
    "print(f\"Validation path: {VALIDATION_PATH}\")\n",
    "print(f\"Test path: {TEST_PATH}\")\n",
    "print(f\"HOG features will be saved to: {HOG_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e296b5b",
   "metadata": {},
   "source": [
    "## HOG Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccfbae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(directory_path):\n",
    "    \"\"\"\n",
    "    Extract HOG features from all images in a directory.\n",
    "    \n",
    "    Args:\n",
    "        directory_path: Path to directory containing image subdirectories (classes)\n",
    "        \n",
    "    Returns:\n",
    "        features: NumPy array of HOG features (shape: [num_images, num_features])\n",
    "        labels: NumPy array of string labels (class names)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Initialize HOG descriptor with fixed parameters for 48x48 images\n",
    "    # These MUST match the parameters used in prediction\n",
    "    hog = cv2.HOGDescriptor(\n",
    "        _winSize=(48, 48),      # Image size (changed to 48x48)\n",
    "        _blockSize=(16, 16),    # Block size\n",
    "        _blockStride=(8, 8),    # Step size for blocks\n",
    "        _cellSize=(8, 8),       # Cell size\n",
    "        _nbins=9                # Number of orientation bins\n",
    "    )\n",
    "    \n",
    "    total_images = 0\n",
    "    \n",
    "    # Loop through each class folder\n",
    "    for class_name in os.listdir(directory_path):\n",
    "        class_path = os.path.join(directory_path, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        \n",
    "        # Loop through each image in the class folder\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            \n",
    "            # Load image in grayscale\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if image is not None:\n",
    "                # Resize to 48x48 pixels\n",
    "                resized_image = cv2.resize(image, (48, 48))\n",
    "                \n",
    "                # Compute HOG features\n",
    "                hog_features = hog.compute(resized_image)\n",
    "                \n",
    "                if hog_features is not None:\n",
    "                    # Flatten and store features\n",
    "                    features.append(hog_features.flatten())\n",
    "                    labels.append(class_name)\n",
    "                    total_images += 1\n",
    "    \n",
    "    print(f\"âœ“ Processed {total_images} images from {os.path.basename(directory_path)}\")\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1c252",
   "metadata": {},
   "source": [
    "## Extract HOG Features for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4006b3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting HOG features from training images...\n",
      "âœ“ Processed 530 images from train\n",
      "Training features shape: (530, 900)\n",
      "Training labels shape: (530,)\n"
     ]
    }
   ],
   "source": [
    "# Extract HOG features from training images\n",
    "print(\"Extracting HOG features from training images...\")\n",
    "train_features, train_labels = extract_hog_features(TRAIN_PATH)\n",
    "print(f\"Training features shape: {train_features.shape}\")\n",
    "print(f\"Training labels shape: {train_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e06708",
   "metadata": {},
   "source": [
    "## Extract HOG Features for Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1de77f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting HOG features from validation images...\n",
      "âœ“ Processed 530 images from validation\n",
      "Validation features shape: (530, 900)\n",
      "Validation labels shape: (530,)\n"
     ]
    }
   ],
   "source": [
    "# Extract HOG features from validation images\n",
    "print(\"\\nExtracting HOG features from validation images...\")\n",
    "validation_features, validation_labels = extract_hog_features(VALIDATION_PATH)\n",
    "print(f\"Validation features shape: {validation_features.shape}\")\n",
    "print(f\"Validation labels shape: {validation_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283754d",
   "metadata": {},
   "source": [
    "## Extract HOG Features for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d35f3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting HOG features from test images...\n",
      "âœ“ Processed 530 images from test\n",
      "Test features shape: (530, 900)\n",
      "Test labels shape: (530,)\n"
     ]
    }
   ],
   "source": [
    "# Extract HOG features from test images\n",
    "print(\"\\nExtracting HOG features from test images...\")\n",
    "test_features, test_labels = extract_hog_features(TEST_PATH)\n",
    "print(f\"Test features shape: {test_features.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4766c9",
   "metadata": {},
   "source": [
    "## Save HOG Features to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b441027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved training HOG features (48x48) and labels\n",
      "âœ“ Saved validation HOG features (48x48) and labels\n",
      "âœ“ Saved test HOG features (48x48) and labels\n",
      "\n",
      "âœ… All 48x48 HOG features saved successfully to: /home/ubuntu/Desktop/AIML project/AlphaNum/hog_features\n",
      "ðŸ“Š Using 48x48 resolution for testing medium-small size\n"
     ]
    }
   ],
   "source": [
    "# Save all HOG features and labels to disk\n",
    "\n",
    "# Save training data\n",
    "np.save(os.path.join(HOG_OUTPUT_PATH, 'train_hog_features_48x48.npy'), train_features)\n",
    "np.save(os.path.join(HOG_OUTPUT_PATH, 'train_labels_48x48.npy'), train_labels)\n",
    "print(\"âœ“ Saved training HOG features (48x48) and labels\")\n",
    "\n",
    "# Save validation data\n",
    "np.save(os.path.join(HOG_OUTPUT_PATH, 'validation_hog_features_48x48.npy'), validation_features)\n",
    "np.save(os.path.join(HOG_OUTPUT_PATH, 'validation_labels_48x48.npy'), validation_labels)\n",
    "print(\"âœ“ Saved validation HOG features (48x48) and labels\")\n",
    "\n",
    "# Save test data\n",
    "np.save(os.path.join(HOG_OUTPUT_PATH, 'test_hog_features_48x48.npy'), test_features)\n",
    "np.save(os.path.join(HOG_OUTPUT_PATH, 'test_labels_48x48.npy'), test_labels)\n",
    "print(\"âœ“ Saved test HOG features (48x48) and labels\")\n",
    "\n",
    "print(f\"\\nâœ… All 48x48 HOG features saved successfully to: {HOG_OUTPUT_PATH}\")\n",
    "print(f\"ðŸ“Š Using 48x48 resolution for testing medium-small size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad1e3b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "HOG features have been extracted and saved for 48x48 images:\n",
    "- **Training data**: `train_hog_features_48x48.npy` and `train_labels_48x48.npy`\n",
    "- **Validation data**: `validation_hog_features_48x48.npy` and `validation_labels_48x48.npy`\n",
    "- **Test data**: `test_hog_features_48x48.npy` and `test_labels_48x48.npy`\n",
    "\n",
    "**Why 48x48?**\n",
    "Testing medium-small resolution:\n",
    "- Smaller than 64x64 for faster processing\n",
    "- Larger than 24x24 for better detail capture\n",
    "- Good balance between accuracy and computational efficiency\n",
    "- Will compare results with other resolutions\n",
    "\n",
    "These files can now be loaded in the main SVM notebook to train the model faster without re-extracting HOG features every time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
